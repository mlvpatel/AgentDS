# =============================================================================
# AgentDS v2.0 Docker Compose
# Complete development and production stack
# Author: Malav Patel
# =============================================================================

version: "3.9"

services:
  # ---------------------------------------------------------------------------
  # AgentDS Web Interface (Gradio)
  # ---------------------------------------------------------------------------
  web:
    build:
      context: ..
      dockerfile: docker/Dockerfile
    container_name: agentds-web
    ports:
      - "7860:7860"
    environment:
      - HOST=0.0.0.0
      - PORT=7860
      - LOG_LEVEL=INFO
      - REDIS_URL=redis://redis:6379/0
      - MLFLOW_TRACKING_URI=http://mlflow:5000
      # LLM API Keys (from .env file)
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-}
      - GROQ_API_KEY=${GROQ_API_KEY:-}
      - OLLAMA_API_BASE=http://ollama:11434
    volumes:
      - ../outputs:/app/outputs
      - ../logs:/app/logs
      - ../config:/app/config:ro
    depends_on:
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:7860/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    restart: unless-stopped
    networks:
      - agentds-network

  # ---------------------------------------------------------------------------
  # AgentDS REST API (Litestar)
  # ---------------------------------------------------------------------------
  api:
    build:
      context: ..
      dockerfile: docker/Dockerfile
    container_name: agentds-api
    command: ["python", "-m", "agentds.web.api.webhooks"]
    ports:
      - "8000:8000"
    environment:
      - HOST=0.0.0.0
      - PORT=8000
      - LOG_LEVEL=INFO
      - REDIS_URL=redis://redis:6379/0
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-}
    volumes:
      - ../outputs:/app/outputs
      - ../logs:/app/logs
    depends_on:
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    networks:
      - agentds-network

  # ---------------------------------------------------------------------------
  # Redis (Caching + Job Queue)
  # ---------------------------------------------------------------------------
  redis:
    image: redis:7-alpine
    container_name: agentds-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes --maxmemory 512mb --maxmemory-policy allkeys-lru
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 3
    restart: unless-stopped
    networks:
      - agentds-network

  # ---------------------------------------------------------------------------
  # MLflow (Experiment Tracking)
  # ---------------------------------------------------------------------------
  mlflow:
    image: ghcr.io/mlflow/mlflow:v2.20.0
    container_name: agentds-mlflow
    ports:
      - "5000:5000"
    volumes:
      - mlflow_data:/mlflow
    command: >
      mlflow server
      --host 0.0.0.0
      --port 5000
      --backend-store-uri sqlite:///mlflow/mlflow.db
      --default-artifact-root /mlflow/artifacts
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    networks:
      - agentds-network
    profiles:
      - full

  # ---------------------------------------------------------------------------
  # Ollama (Local LLM Inference)
  # ---------------------------------------------------------------------------
  ollama:
    image: ollama/ollama:latest
    container_name: agentds-ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    networks:
      - agentds-network
    profiles:
      - local-llm

  # ---------------------------------------------------------------------------
  # RQ Worker (Background Jobs)
  # ---------------------------------------------------------------------------
  worker:
    build:
      context: ..
      dockerfile: docker/Dockerfile
    container_name: agentds-worker
    command: ["python", "-m", "rq.cli", "worker", "--url", "redis://redis:6379/0"]
    environment:
      - REDIS_URL=redis://redis:6379/0
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-}
    volumes:
      - ../outputs:/app/outputs
      - ../logs:/app/logs
    depends_on:
      redis:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - agentds-network
    profiles:
      - full

# =============================================================================
# Volumes
# =============================================================================
volumes:
  redis_data:
    name: agentds-redis-data
  mlflow_data:
    name: agentds-mlflow-data
  ollama_data:
    name: agentds-ollama-data

# =============================================================================
# Networks
# =============================================================================
networks:
  agentds-network:
    name: agentds-network
    driver: bridge
